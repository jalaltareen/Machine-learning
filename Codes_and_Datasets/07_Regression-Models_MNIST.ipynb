{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T6g4dnLtxDll"
   },
   "source": [
    "# Regression Models - MNIST Dataset\n",
    "\n",
    "A presentation of this dataset together with an exploratory analysis has been done already in another notebook of this repository (click here to access it: [An Unsupervised Approach to MNIST](https://github.com/LeviGuerra/Machine-Learning-Portfolio/blob/master/Codes_and_Datasets/06_An-Unsupervised-Approach-to-MNIST.ipynb)).\n",
    "\n",
    "Here the MNIST problem will be solved by supervised means. Concretely, after a dimensional reduction, we will use different regression/classification methods.\n",
    "\n",
    "### Table of Contents\n",
    "- [0. Loading the Dataset](#0.-Loading-the-Dataset)\n",
    "- [1. Dimensional Reduction: PCA](#1.-Dimensional-Reduction:-PCA)\n",
    "- [2. Solutions of the Problem: Regression Models](#2.-Solutions-of-the-Problem:-Regression-Models)\n",
    "    - [2.1 Linear Regression](#2.1-Linear-Regression)\n",
    "    - [2.2 Polynomial Regression](#2.2-Polynomial-Regression)\n",
    "    - [2.3 Logistic Regression (Classification)](#2.3-Logistic-Regression-(Classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QueRcnJ1yHC9"
   },
   "source": [
    "## 0. Loading the Dataset\n",
    "\n",
    "[The dataset was obtained from Google Colab sample_data.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kdXCOf515bvG",
    "outputId": "c99e4d6a-2517-4246-9f0e-2c53bcac7f11",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import sklearn as sk\n",
    "import pandas  as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is: (20000, 785)\n",
      "\n",
      "[[6 0 0 ... 0 0 0]\n",
      " [5 0 0 ... 0 0 0]\n",
      " [7 0 0 ... 0 0 0]\n",
      " ...\n",
      " [2 0 0 ... 0 0 0]\n",
      " [9 0 0 ... 0 0 0]\n",
      " [5 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "mnist = pd.read_csv('Datasets/MNIST.csv', header=None)\n",
    "mnist = np.array(mnist)\n",
    "print('The shape of the dataset is:',mnist.shape)\n",
    "print()\n",
    "print(mnist)\n",
    "\n",
    "X = mnist[:,1:]\n",
    "Y = mnist[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dimensional Reduction: PCA\n",
    "\n",
    "We choose the smallest subset of variables able to represent at least the 50% of the original variance. And thus, the system is reduced to 11 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "S9BQ90ekHcrI",
    "outputId": "c44f93f3-5e87-48ac-c7ed-1e6c1638b9ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 11)\n"
     ]
    }
   ],
   "source": [
    "x=X\n",
    "ipca = PCA(n_components=0.5)\n",
    "ipca.fit(x)\n",
    "xt = ipca.transform(x)\n",
    "\n",
    "print(xt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Solutions of the Problem: Regression Models\n",
    "\n",
    "The accuracies obtained for polynomial regressions grow with the degree of polynomial until we reach a degree 6, where a small decay in accuracy appears, most likely due to overfitting. The highest value is obtained for the logistic regression; this shouldn't be surprising, since it's a classification technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eAdQpstuse2L",
    "outputId": "2cd4c1ce-5c9b-4f56-854b-08c931dfbacd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of Linear Regression after 100 iterations = 13.95 %\n"
     ]
    }
   ],
   "source": [
    "acclist = []\n",
    "iterations=100\n",
    "\n",
    "for i in range(iterations):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(xt,Y, test_size=0.3)\n",
    "    regr_lineal = linear_model.LinearRegression()\n",
    "    regr_lineal.fit(X_train, Y_train)#[:, np.newaxis])\n",
    "    Ypred = regr_lineal.predict(X_test)\n",
    "    acc = np.sum(np.round(Ypred) == Y_test)/len(Y_test)\n",
    "    acclist.append(acc)\n",
    "\n",
    "print('Mean accuracy of Linear Regression after',iterations,'iterations =', round(np.mean(acclist)*100,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "fIObaFPBpOrY",
    "outputId": "24dd6af6-3b4b-45f6-ca50-420ec32ce4fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Polynomial Regression for degree 1 = 13.43 %\n",
      "Accuracy of Polynomial Regression for degree 2 = 27.02 %\n",
      "Accuracy of Polynomial Regression for degree 3 = 35.6 %\n",
      "Accuracy of Polynomial Regression for degree 4 = 43.03 %\n",
      "Accuracy of Polynomial Regression for degree 5 = 41.3 %\n"
     ]
    }
   ],
   "source": [
    "pol_acc_list = []\n",
    "max_grados = 5\n",
    "\n",
    "for gr in range(1, max_grados+1):\n",
    "    pol = PolynomialFeatures(gr)\n",
    "    # Polynomial Transformation of X\n",
    "    x_pol = pol.fit_transform(xt)\n",
    "  \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(x_pol,Y, test_size=0.3)\n",
    "    \n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X_train, Y_train)\n",
    "    y_pol_pred = model.predict(X_test)\n",
    "    pol_acc = np.sum(np.round(y_pol_pred) == Y_test)/len(Y_test)\n",
    "    pol_acc_list.append(pol_acc)\n",
    "    print('Accuracy of Polynomial Regression for degree',gr,'=', round(np.mean(pol_acc_list)*100,2),'%')\n",
    "    pol_acc_list=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Logistic Regression (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XTlXHMtpavjI",
    "outputId": "6aa17091-fcbf-4744-d30c-558b0b46132e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of Logistic Regression after 5 iterations = 80.77 %\n"
     ]
    }
   ],
   "source": [
    "iterations = 5\n",
    "acc = []\n",
    "acc_log= []\n",
    "  \n",
    "for i in range(iterations):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(xt,Y, test_size=0.3)\n",
    "    lo = LogisticRegression(multi_class='multinomial', solver=\"lbfgs\",max_iter=5000,verbose=0).fit(X_train, \n",
    "                                                                                                   Y_train)\n",
    "    acc_log.append(lo.score(X_test, Y_test))\n",
    "print('Mean accuracy of Logistic Regression after',iterations,'iterations =', round(np.mean(acc_log)*100,2),'%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exerc.7 - Semisupervisado MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
